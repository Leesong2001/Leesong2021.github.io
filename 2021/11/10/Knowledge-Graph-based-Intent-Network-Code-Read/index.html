<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.1">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.1" color="#222">
  <meta name="google-site-verification" content="1TSpI3V3af8vd0EtsjdHFFSQr-O_2Qw1uiHQk2QjURM"/>
  <meta name="baidu-site-verification" content="true">

<link rel="stylesheet" href="/css/main.css?v=7.4.1">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="/lib/pace/pace-theme-corner-indicator.min.css?v=1.0.2">
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.4.1',
    exturl: false,
    sidebar: {"position":"left","width":240,"display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":2,"unescape":false,"preload":true},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="Knowledge_Graph_based_Intent_Network 源码阅读笔记">
<meta name="keywords" content="RecSys">
<meta property="og:type" content="article">
<meta property="og:title" content="Knowledge_Graph_based_Intent_Network_Code">
<meta property="og:url" content="https://leesong2001.github.io/2021/11/10/Knowledge-Graph-based-Intent-Network-Code-Read/index.html">
<meta property="og:site_name" content="SteinsGate">
<meta property="og:description" content="Knowledge_Graph_based_Intent_Network 源码阅读笔记">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://leesong2001.github.io/2021/11/10/Knowledge-Graph-based-Intent-Network-Code-Read/毕业设计/img/51fAmVkTbyL._SY300_.jpg">
<meta property="og:image" content="https://leesong2001.github.io/2021/11/10/Knowledge-Graph-based-Intent-Network-Code-Read/毕业设计/img/nodeInKGEmbedding.png">
<meta property="og:image" content="https://leesong2001.github.io/2021/11/10/Knowledge-Graph-based-Intent-Network-Code-Read/毕业设计/img/scatter_mean.png">
<meta property="og:image" content="https://leesong2001.github.io/2021/11/10/Knowledge-Graph-based-Intent-Network-Code-Read/毕业设计/img/AggregationLayerOverKG.png">
<meta property="og:updated_time" content="2021-11-20T16:33:02.286Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Knowledge_Graph_based_Intent_Network_Code">
<meta name="twitter:description" content="Knowledge_Graph_based_Intent_Network 源码阅读笔记">
<meta name="twitter:image" content="https://leesong2001.github.io/2021/11/10/Knowledge-Graph-based-Intent-Network-Code-Read/毕业设计/img/51fAmVkTbyL._SY300_.jpg">
  <link rel="canonical" href="https://leesong2001.github.io/2021/11/10/Knowledge-Graph-based-Intent-Network-Code-Read/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Knowledge_Graph_based_Intent_Network_Code | SteinsGate</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">SteinsGate</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Good luck to you !! My Friends.</p>
      
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-schedule">
      
    

    <a href="/schedule/" rel="section"><i class="fa fa-fw fa-calendar"></i>日程表</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-sitemap">
      
    

    <a href="/sitemap.xml" rel="section"><i class="fa fa-fw fa-sitemap"></i>站点地图</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-commonweal">
      
    

    <a href="/404/" rel="section"><i class="fa fa-fw fa-heartbeat"></i>公益 404</a>

  </li>
      <li class="menu-item menu-item-search">
        <a href="javascript:;" class="popup-trigger">
        
          <i class="fa fa-search fa-fw"></i>搜索</a>
      </li>
    
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/leesong2001" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://leesong2001.github.io/2021/11/10/Knowledge-Graph-based-Intent-Network-Code-Read/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="李松">
      <meta itemprop="description" content="NoGameNoLife">
      <meta itemprop="image" content="/images/MyAvatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SteinsGate">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">Knowledge_Graph_based_Intent_Network_Code

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2021-11-10 15:26:57" itemprop="dateCreated datePublished" datetime="2021-11-10T15:26:57+08:00">2021-11-10</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-11-21 00:33:02" itemprop="dateModified" datetime="2021-11-21T00:33:02+08:00">2021-11-21</time>
              </span>
            
          

          
          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
              
                <span class="post-meta-item-text">本文字数：</span>
              
              <span>50k</span>
            </span>
          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
              
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              
              <span>45 分钟</span>
            </span>
          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Knowledge_Graph_based_Intent_Network 源码阅读笔记</p>
<a id="more"></a>
<h1 id="源码目录结构"><a href="#源码目录结构" class="headerlink" title="源码目录结构"></a>源码目录结构</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Knowledge_Graph_based_Intent_Network</span><br><span class="line">|--data</span><br><span class="line">|  |--alibaba-fashion</span><br><span class="line">|  |--amazon-book</span><br><span class="line">|  |--last-fm</span><br><span class="line">|--modules</span><br><span class="line">|  |--KGIN.py</span><br><span class="line">|--training_log</span><br><span class="line">|--utils</span><br><span class="line">|  |--data_loader.py</span><br><span class="line">|  |--evaluate.py</span><br><span class="line">|  |--helper.py</span><br><span class="line">|  |--metric.py</span><br><span class="line">|  |--parser.py</span><br><span class="line">|--main.py</span><br><span class="line">|--README.m\d</span><br></pre></td></tr></table></figure>
<h1 id="data"><a href="#data" class="headerlink" title="data"></a>data</h1><script type="math/tex; mode=display">
\Large e_{i}^{(l)}=\frac{1}{|N_{i}|}\sum_{(r,v)\in N_{i}}{e_{r}\odot e_{v}^{l-1}}\\
\Large N_{i}=\{(r,v)|(i,r,v)\in G\}\\

\Large e_{i}^{(l)}=f_{KG}(\{(e_{i}^{l-1},e_{r},e_{v}^{l-1})|(r,v)\in N_{i}\})\\
\Large e_{i}^{(l)}=\sum_{s\in N_{i}^{l}}{\frac{e_{r_{1}}}{|N_{s_{1}}|}\odot\frac{e_{r_{2}}}{|N_{s_{2}}|}\odot \cdots \odot\frac{e_{r_{l}}}{|N_{s_{l}}|}\odot e_{s_{l}}^{(0)}}</script><p>data文件夹下存放着三个数据集：alibaba-fashion，amazon-book，last-fm</p>
<p>格式大抵相同，以amazon-book为例，完整数据在<a href="https://nijianmo.github.io/amazon/index.html#sample-metadata" target="_blank" rel="noopener">Amazon Review Data</a></p>
<p>可能的格式如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"asin"</span>: <span class="string">"0000031852"</span>,</span><br><span class="line">  <span class="string">"title"</span>: <span class="string">"Girls Ballet Tutu Zebra Hot Pink"</span>,</span><br><span class="line">  <span class="string">"feature"</span>: [<span class="string">"Botiquecutie Trademark exclusive Brand"</span>,</span><br><span class="line">              <span class="string">"Hot Pink Layered Zebra Print Tutu"</span>,</span><br><span class="line">              <span class="string">"Fits girls up to a size 4T"</span>,</span><br><span class="line">              <span class="string">"Hand wash / Line Dry"</span>,</span><br><span class="line">              <span class="string">"Includes a Botiquecutie TM Exclusive hair flower bow"</span>],</span><br><span class="line">  <span class="string">"description"</span>: <span class="string">"This tutu is great for dress up play for your little ballerina. Botiquecute Trade Mark exclusive brand. Hot Pink Zebra print tutu."</span>, </span><br><span class="line">  <span class="string">"price"</span>: <span class="number">3.17</span>,</span><br><span class="line">  <span class="string">"imageURL"</span>: <span class="string">"http://ecx.images-amazon.com/images/I/51fAmVkTbyL._SY300_.jpg"</span>,</span><br><span class="line">  <span class="string">"imageURLHighRes"</span>: <span class="string">"http://ecx.images-amazon.com/images/I/51fAmVkTbyL.jpg"</span>,</span><br><span class="line">  <span class="string">"also_buy"</span>: [<span class="string">"B00JHONN1S"</span>, <span class="string">"B002GZGI4E"</span>, <span class="string">"B001T9NUFS"</span>, <span class="string">"B002R0F7FE"</span>, <span class="string">"B00E1YRI4C"</span>, <span class="string">"B008UBQZKU"</span>, <span class="string">"B00D103F8U"</span>, <span class="string">"B007R2RM8W"</span>],</span><br><span class="line">  <span class="string">"also_viewed"</span>: [<span class="string">"B002BZX8Z6"</span> <span class="string">"B00E79VW6Q"</span>, <span class="string">"B00D10CLVW"</span>, <span class="string">"B00B0AVO54"</span>, <span class="string">"B00E95LC8Q"</span>, <span class="string">"B00GOR92SO"</span>, <span class="string">"B007ZN5Y56"</span>, <span class="string">"B00AL2569W"</span>, <span class="string">"B00B608000"</span>, <span class="string">"B008F0SMUC"</span>, <span class="string">"B00BFXLZ8M"</span>],</span><br><span class="line">  <span class="string">"salesRank"</span>: &#123;<span class="string">"Toys &amp; Games"</span>: <span class="number">211836</span>&#125;,</span><br><span class="line">  <span class="string">"brand"</span>: <span class="string">"Coxlures"</span>,</span><br><span class="line">  <span class="string">"categories"</span>: [[<span class="string">"Sports &amp; Outdoors"</span>, <span class="string">"Other Sports"</span>, <span class="string">"Dance"</span>]]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里下载<strong>imageURL</strong>中指示的图片，如下</p>
<p><img src="/2021/11/10/Knowledge-Graph-based-Intent-Network-Code-Read/毕业设计\img\51fAmVkTbyL._SY300_.jpg" alt></p>
<p>符合<strong>description</strong>中描述的This tutu is great for <strong>dress up play for your little ballerina</strong>. Botiquecute Trade Mark exclusive brand. <strong>Hot Pink Zebra print tutu.</strong>（这套芭蕾短裙非常适合你的小芭蕾舞演员装扮。Botiquecute商标独家品牌。粉色斑马印花短裙）</p>
<h2 id="amazon-book"><a href="#amazon-book" class="headerlink" title="amazon-book"></a>amazon-book</h2><p>entity_list.txt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">org_id remap_id</span><br><span class="line">m.045wq1q 0</span><br><span class="line">m.03_28m 1</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>item_list.txt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">org_id remap_id freebase_id</span><br><span class="line">0553092626 0 m.045wq1q</span><br><span class="line">0393316041 1 m.03_28m</span><br><span class="line">038548254X 2 m.0h2q1cq</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>kg_final.txt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">24915 0 24916</span><br><span class="line">24917 1 5117</span><br><span class="line">24918 0 24917</span><br><span class="line">24919 1 24920</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>relation_list.txt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">org_id remap_id</span><br><span class="line">http://rdf.freebase.com/ns/type.object.type 0</span><br><span class="line">http://rdf.freebase.com/ns/type.type.instance 1</span><br><span class="line">http://rdf.freebase.com/ns/book.written_work.copyright_date 2</span><br><span class="line">http://www.w3.org/1999/02/22-rdf-syntax-ns#type 3`</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>train.txt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">0 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31</span><br><span class="line">1 32 33 34 35</span><br><span class="line">2 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51</span><br><span class="line">3 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>test.txt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">0 4828 774 207 7460 7465 3768 10221 22435</span><br><span class="line">1 2825</span><br><span class="line">2 10184 3500 10241 10185 1700</span><br><span class="line">3 5365 699 3016 6675</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>user_list.txt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">org_id remap_id</span><br><span class="line">A3RTKL9KB8KLID 0</span><br><span class="line">A38LAIK2N83NH0 1</span><br><span class="line">A3PPXVR5J6U2JD 2</span><br><span class="line">A2ULDDL3MLJPUR 3</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h1 id="源码中的一些技术-库简介"><a href="#源码中的一些技术-库简介" class="headerlink" title="源码中的一些技术/库简介"></a>源码中的一些技术/库简介</h1><h2 id="tqdm"><a href="#tqdm" class="headerlink" title="tqdm"></a>tqdm</h2><p>Tqdm 是一个快速，可扩展的Python进度条，可以在 Python 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器 tqdm(iterator)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> char <span class="keyword">in</span> tqdm([<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"d"</span>]):</span><br><span class="line">    <span class="comment">#do something</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>效果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">100%|███████████████████████████████████| 857K/857K [00:04&lt;00:00, 246Kloc/s]</span><br></pre></td></tr></table></figure>
<h2 id="图结构表示"><a href="#图结构表示" class="headerlink" title="图结构表示"></a>图结构表示</h2><p>拉普拉斯矩阵</p>
<h2 id="稀疏矩阵"><a href="#稀疏矩阵" class="headerlink" title="稀疏矩阵"></a>稀疏矩阵</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scipy.CSR</span><br></pre></td></tr></table></figure>
<h1 id="main-py"><a href="#main-py" class="headerlink" title="main.py"></a>main.py</h1><h2 id="设置随机种子"><a href="#设置随机种子" class="headerlink" title="设置随机种子"></a>设置随机种子</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""fix the random seed"""</span></span><br><span class="line">    seed = <span class="number">2020</span></span><br><span class="line">    random.seed(seed)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed_all(seed)</span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h2 id="从命令行中读取参数"><a href="#从命令行中读取参数" class="headerlink" title="从命令行中读取参数"></a>从命令行中读取参数</h2><p>   命令行示例：<code>python main.py --dataset last-fm --dim 64 --lr 0.0001 --sim_regularity 0.0001 --batch_size 1024 --node_dropout True --node_dropout_rate 0.5 --mess_dropout True --mess_dropout_rate 0.1 --gpu_id 0 --context_hops 3</code></p>
   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""read args"""</span></span><br><span class="line">    <span class="keyword">global</span> args, device</span><br><span class="line">    args = parse_args()</span><br><span class="line">    device = torch.device(<span class="string">"cuda:"</span>+str(args.gpu_id)) <span class="keyword">if</span> args.cuda <span class="keyword">else</span> torch.device(<span class="string">"cpu"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="构建数据集"><a href="#构建数据集" class="headerlink" title="构建数据集"></a>构建数据集</h2>   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""build dataset"""</span></span><br><span class="line">    train_cf, test_cf, user_dict, n_params, graph, mat_list = load_data(args)</span><br><span class="line">    adj_mat_list, norm_mat_list, mean_mat_list = mat_list</span><br><span class="line"></span><br><span class="line">    n_users = n_params[<span class="string">'n_users'</span>]</span><br><span class="line">    n_items = n_params[<span class="string">'n_items'</span>]</span><br><span class="line">    n_entities = n_params[<span class="string">'n_entities'</span>]</span><br><span class="line">    n_relations = n_params[<span class="string">'n_relations'</span>]</span><br><span class="line">    n_nodes = n_params[<span class="string">'n_nodes'</span>]</span><br></pre></td></tr></table></figure>
<p>   深入到<code>load_data(args)</code>中查看</p>
   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(model_args)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> args</span><br><span class="line">    args = model_args</span><br><span class="line">    directory = args.data_path + args.dataset + <span class="string">'/'</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">'reading train and test user-item set ...'</span>)</span><br><span class="line">    train_cf = read_cf(directory + <span class="string">'train.txt'</span>)</span><br><span class="line">    test_cf = read_cf(directory + <span class="string">'test.txt'</span>)</span><br><span class="line">    </span><br><span class="line">    remap_item(train_cf, test_cf)</span><br></pre></td></tr></table></figure>
<p>   <code>read_cf()</code>在data_loader.py中，输入参数为file_name，读取的数据集文件介绍如下</p>
<ul>
<li><p><code>train.txt</code></p>
<p>Train file.</p>
<p>Each line is a user with her/his positive interactions with items: (<code>userID</code> and <code>a list of itemID</code>).</p>
</li>
<li><p><code>test.txt</code></p>
<p>Test file (positive instances).</p>
<p>Each line is a user with her/his positive interactions with items: (<code>userID</code> and <code>a list of itemID</code>).</p>
<p>Note that here we treat all unobserved interactions as the negative instances when reporting performance.</p>
<p><code>read_cf()</code>的作用是得到每个用户的交互记录，具体的做法是将<code>a list of itemID</code>打散和<code>userID</code>配对，返回numpyArray[<uid,itemid>,]</uid,itemid></p>
</li>
</ul>
<p>   <code>remap_item</code>的作用是输入 numpyArray[<uid,itemid>,]，返回一个KV字典结构dict{ uid : List[itemid] }，同时给<code>n_users</code>和<code>n_items</code>分别赋值为<strong>测试集和训练集并集</strong>中最大的的用户ID和物品ID</uid,itemid></p>
   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'combinating train_cf and kg data ...'</span>)</span><br><span class="line">triplets = read_triplets(directory + <span class="string">'kg_final.txt'</span>)</span><br></pre></td></tr></table></figure>
<p>   read_triplets根据输入参数<code>inverse_r</code>决定最后得到的triplets的relation是否反向，若<code>inverse_r</code>为False，则直接读入<strong>data/kg_final.txt</strong>中的三元组数据<entity,rel,entity>，同时完成n_entities, n_relations, n_nodes的赋值</entity,rel,entity></p>
   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'building the graph ...'</span>)</span><br><span class="line">graph, relation_dict = build_graph(train_cf, triplets)</span><br></pre></td></tr></table></figure>
<p><code>ckg_graph.add_edge(h_id, t_id, key=r_id)</code>   </p>
<p>如上，graph是调用networkx，根据triplets三元组中的头结点、尾结点、关系ID建立的有向图，该对象对应着知识图谱。通过将关系ID传入add_edge函数的key参数以区分不同的边。relation_dict则是一个字典结构dict{ relation :  List[]}，其中relation_dict[0]存储的是用户的交互数据，即List[<uid,itemid>, ]，而relation[非0]存储的是知识图谱中的指向关系，即List[<entity1,entity2>, ]</entity1,entity2></uid,itemid></p>
   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'building the adj mat ...'</span>)</span><br><span class="line">adj_mat_list, norm_mat_list, mean_mat_list = build_sparse_relational_graph(relation_dict)</span><br></pre></td></tr></table></figure>
<p>   深入到<code>build_sparse_relational_graph()</code>中分析</p>
   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_sparse_relational_graph</span><span class="params">(relation_dict)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_bi_norm_lap</span><span class="params">(adj)</span>:</span></span><br><span class="line">        <span class="comment"># D^&#123;-1/2&#125;AD^&#123;-1/2&#125;</span></span><br><span class="line">        rowsum = np.array(adj.sum(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        d_inv_sqrt = np.power(rowsum, <span class="number">-0.5</span>).flatten()</span><br><span class="line">        d_inv_sqrt[np.isinf(d_inv_sqrt)] = <span class="number">0.</span></span><br><span class="line">        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># bi_lap = adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt)</span></span><br><span class="line">        bi_lap = d_mat_inv_sqrt.dot(adj).dot(d_mat_inv_sqrt)</span><br><span class="line">        <span class="keyword">return</span> bi_lap.tocoo()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_si_norm_lap</span><span class="params">(adj)</span>:</span></span><br><span class="line">        <span class="comment"># D^&#123;-1&#125;A</span></span><br><span class="line">        rowsum = np.array(adj.sum(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        d_inv = np.power(rowsum, <span class="number">-1</span>).flatten()</span><br><span class="line">        d_inv[np.isinf(d_inv)] = <span class="number">0.</span></span><br><span class="line">        d_mat_inv = sp.diags(d_inv)</span><br><span class="line"></span><br><span class="line">        norm_adj = d_mat_inv.dot(adj)</span><br><span class="line">        <span class="keyword">return</span> norm_adj.tocoo()</span><br></pre></td></tr></table></figure>
<p>_bi_norm_lap(adj)：对每一个矩阵A（adj）进行归一化，生成拉普拉斯矩阵；先算出度矩阵D（rowsum），然后对D做处理，没值的赋0，然后铺在对角线，最后对adj进行对称归一化，生成拉普拉斯矩阵 。拉普拉斯矩阵是图论中用到的一种重要矩阵，给定一个有n个顶点的图 G=(V,E)，其拉普拉斯矩阵被定义为 L = D-A，D为图的度矩阵，A为图的邻接矩阵。</p>
   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">adj_mat_list = []</span><br><span class="line">print(<span class="string">"Begin to build sparse relation matrix ..."</span>)</span><br><span class="line"><span class="keyword">for</span> r_id <span class="keyword">in</span> tqdm(relation_dict.keys()):</span><br><span class="line">    np_mat = np.array(relation_dict[r_id])</span><br><span class="line">    <span class="keyword">if</span> r_id == <span class="number">0</span>:<span class="comment"># user-item 交互数据</span></span><br><span class="line">        cf = np_mat.copy()</span><br><span class="line">        cf[:, <span class="number">1</span>] = cf[:, <span class="number">1</span>] + n_users  <span class="comment"># [0, n_items) -&gt; [n_users, n_users+n_items)</span></span><br><span class="line">        vals = [<span class="number">1.</span>] * len(cf)<span class="comment"># &lt;user,item,interactionRate=1.0&gt;</span></span><br><span class="line">        adj = sp.coo_matrix((vals, (cf[:, <span class="number">0</span>], cf[:, <span class="number">1</span>])), shape=(n_nodes, n_nodes))</span><br></pre></td></tr></table></figure>
<p>   <code>scipy.coo_matrix</code>可根据输入构建稀疏矩阵，输入格式为[row,col,value]，具体的调用方式如上所示<code>coo_matrix((val, (row, col)), shape=(rowSize, colSize))</code></p>
   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span>:</span><br><span class="line">	<span class="comment">#知识图谱中的实体-实体关系</span></span><br><span class="line">    vals = [<span class="number">1.</span>] * len(np_mat)</span><br><span class="line">    adj = sp.coo_matrix((vals, (np_mat[:, <span class="number">0</span>], np_mat[:, <span class="number">1</span>])), shape=(n_nodes, n_nodes))</span><br><span class="line">adj_mat_list.append(adj)</span><br></pre></td></tr></table></figure>
<p>   adj_mat_list：List[coo_matrix[user,item],coo_matrix[entity,entity],coo_matrix[entity,entity]……]</p>
<p>   其索引为 0号relation：user-item interaction 以及 非0号relation：entity-entity知识图谱上的实体关系</p>
   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">norm_mat_list = [_bi_norm_lap(mat) <span class="keyword">for</span> mat <span class="keyword">in</span> adj_mat_list]</span><br><span class="line">mean_mat_list = [_si_norm_lap(mat) <span class="keyword">for</span> mat <span class="keyword">in</span> adj_mat_list]</span><br><span class="line"><span class="comment"># interaction: user-&gt;item, [n_users, n_entities]</span></span><br><span class="line">norm_mat_list[<span class="number">0</span>] = norm_mat_list[<span class="number">0</span>].tocsr()[:n_users, n_users:].tocoo()</span><br><span class="line">mean_mat_list[<span class="number">0</span>] = mean_mat_list[<span class="number">0</span>].tocsr()[:n_users, n_users:].tocoo()</span><br><span class="line">   </span><br><span class="line"><span class="keyword">return</span> adj_mat_list, norm_mat_list, mean_mat_list</span><br></pre></td></tr></table></figure>
<p>   <code>norm_mat_list[0] = norm_mat_list[0].tocsr()[:n_users, n_users:].tocoo()</code>看起来是将矩阵[user&amp;item,user&amp;item]切分，仅保留[user,item]交互矩阵，即行代表user，列代表item。对这部分代码做一个简单测试，输出切分前后的矩阵形状。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">norm_mat_list[0] = norm_mat_list[0].tocsr().shape=(129955, 129955)</span><br><span class="line">norm_mat_list[0] = norm_mat_list[0].tocsr()[:n_users, n_users:].shape=(23566, 106389)</span><br></pre></td></tr></table></figure>
<p>验证了上面的分析。</p>
   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">n_params = &#123;</span><br><span class="line">    <span class="string">'n_users'</span>: int(n_users),</span><br><span class="line">    <span class="string">'n_items'</span>: int(n_items),</span><br><span class="line">    <span class="string">'n_entities'</span>: int(n_entities),</span><br><span class="line">    <span class="string">'n_nodes'</span>: int(n_nodes),</span><br><span class="line">    <span class="string">'n_relations'</span>: int(n_relations)</span><br><span class="line">&#125;</span><br><span class="line">user_dict = &#123;</span><br><span class="line">    <span class="string">'train_user_set'</span>: train_user_set,</span><br><span class="line">    <span class="string">'test_user_set'</span>: test_user_set</span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line"><span class="keyword">return</span> train_cf, test_cf, user_dict, n_params, graph, \</span><br><span class="line">       [adj_mat_list, norm_mat_list, mean_mat_list]</span><br></pre></td></tr></table></figure>
<h2 id="协同过滤数据"><a href="#协同过滤数据" class="headerlink" title="协同过滤数据"></a>协同过滤数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""cf data"""</span></span><br><span class="line">    train_cf_pairs = torch.LongTensor(np.array([[cf[<span class="number">0</span>], cf[<span class="number">1</span>]] <span class="keyword">for</span> cf <span class="keyword">in</span> train_cf], np.int32))</span><br><span class="line">    test_cf_pairs = torch.LongTensor(np.array([[cf[<span class="number">0</span>], cf[<span class="number">1</span>]] <span class="keyword">for</span> cf <span class="keyword">in</span> test_cf], np.int32))</span><br></pre></td></tr></table></figure>
<h2 id="模型定义"><a href="#模型定义" class="headerlink" title="模型定义"></a>模型定义</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""define model"""</span></span><br><span class="line">model = Recommender(n_params, args, graph, mean_mat_list[<span class="number">0</span>]).to(device)</span><br></pre></td></tr></table></figure>
<h2 id="优化器定义"><a href="#优化器定义" class="headerlink" title="优化器定义"></a>优化器定义</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""define optimizer"""</span></span><br><span class="line">	optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)</span><br></pre></td></tr></table></figure>
<h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">cur_best_pre_0 = <span class="number">0</span></span><br><span class="line">   stopping_step = <span class="number">0</span></span><br><span class="line">   should_stop = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">   print(<span class="string">"start training ..."</span>)</span><br><span class="line">   <span class="keyword">for</span> epoch <span class="keyword">in</span> range(args.epoch):</span><br><span class="line">       <span class="string">"""training CF"""</span></span><br><span class="line">       <span class="comment"># shuffle training data</span></span><br><span class="line">       <span class="comment">#train_cf &lt;user,item&gt;   每一行对应着一个用户物品对的交互记录 </span></span><br><span class="line">       index = np.arange(len(train_cf))</span><br><span class="line">       np.random.shuffle(index)<span class="comment"># 打乱</span></span><br><span class="line">       train_cf_pairs = train_cf_pairs[index]<span class="comment"># 取打乱后的train_cf_pairs</span></span><br><span class="line"></span><br><span class="line">       <span class="string">"""training"""</span></span><br><span class="line">       loss, s, cor_loss = <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">       train_s_t = time()</span><br><span class="line">       <span class="keyword">while</span> s + args.batch_size &lt;= len(train_cf):</span><br><span class="line">           batch = get_feed_dict(train_cf_pairs,</span><br><span class="line">                                 s, s + args.batch_size,</span><br><span class="line">                                 user_dict[<span class="string">'train_user_set'</span>])</span><br><span class="line">           batch_loss, _, _, batch_cor = model(batch)</span><br><span class="line"></span><br><span class="line">           batch_loss = batch_loss</span><br><span class="line">           optimizer.zero_grad()</span><br><span class="line">           batch_loss.backward()</span><br><span class="line">           optimizer.step()</span><br><span class="line"></span><br><span class="line">           loss += batch_loss</span><br><span class="line">           cor_loss += batch_cor</span><br><span class="line">           s += args.batch_size</span><br><span class="line"></span><br><span class="line">       train_e_t = time()</span><br><span class="line"></span><br><span class="line">       <span class="keyword">if</span> epoch % <span class="number">10</span> == <span class="number">9</span> <span class="keyword">or</span> epoch == <span class="number">1</span>:</span><br><span class="line">           <span class="string">"""testing"""</span></span><br><span class="line">           test_s_t = time()</span><br><span class="line">           ret = test(model, user_dict, n_params)</span><br><span class="line">           test_e_t = time()</span><br><span class="line"></span><br><span class="line">           train_res = PrettyTable()</span><br><span class="line">           train_res.field_names = [<span class="string">"Epoch"</span>, <span class="string">"training time"</span>, <span class="string">"tesing time"</span>, <span class="string">"Loss"</span>, <span class="string">"recall"</span>, <span class="string">"ndcg"</span>, <span class="string">"precision"</span>, <span class="string">"hit_ratio"</span>]</span><br><span class="line">           train_res.add_row(</span><br><span class="line">               [epoch, train_e_t - train_s_t, test_e_t - test_s_t, loss.item(), ret[<span class="string">'recall'</span>], ret[<span class="string">'ndcg'</span>], ret[<span class="string">'precision'</span>], ret[<span class="string">'hit_ratio'</span>]]</span><br><span class="line">           )</span><br><span class="line">           print(train_res)</span><br><span class="line"></span><br><span class="line">           <span class="comment"># *********************************************************</span></span><br><span class="line">           <span class="comment"># early stopping when cur_best_pre_0 is decreasing for ten successive steps.</span></span><br><span class="line">           cur_best_pre_0, stopping_step, should_stop = early_stopping(ret[<span class="string">'recall'</span>][<span class="number">0</span>], cur_best_pre_0,</span><br><span class="line">                                                                       stopping_step, expected_order=<span class="string">'acc'</span>,</span><br><span class="line">                                                                       flag_step=<span class="number">10</span>)</span><br><span class="line">           <span class="keyword">if</span> should_stop:</span><br><span class="line">               <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">           <span class="string">"""save weight"""</span></span><br><span class="line">           <span class="keyword">if</span> ret[<span class="string">'recall'</span>][<span class="number">0</span>] == cur_best_pre_0 <span class="keyword">and</span> args.save:</span><br><span class="line">               torch.save(model.state_dict(), args.out_dir + <span class="string">'model_'</span> + args.dataset + <span class="string">'.ckpt'</span>)</span><br><span class="line"></span><br><span class="line">       <span class="keyword">else</span>:</span><br><span class="line">           <span class="comment"># logging.info('training loss at epoch %d: %f' % (epoch, loss.item()))</span></span><br><span class="line">           print(<span class="string">'using time %.4f, training loss at epoch %d: %.4f, cor: %.6f'</span> % (train_e_t - train_s_t, epoch, loss.item(), cor_loss.item()))</span><br><span class="line"></span><br><span class="line">   print(<span class="string">'early stopping at %d, recall@20:%.4f'</span> % (epoch, cur_best_pre_0))</span><br></pre></td></tr></table></figure>
<h1 id="data-loader-py"><a href="#data-loader-py" class="headerlink" title="data_loader.py"></a>data_loader.py</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br><span class="line"></span><br><span class="line">n_users = <span class="number">0</span></span><br><span class="line">n_items = <span class="number">0</span></span><br><span class="line">n_entities = <span class="number">0</span></span><br><span class="line">n_relations = <span class="number">0</span></span><br><span class="line">n_nodes = <span class="number">0</span></span><br><span class="line">train_user_set = defaultdict(list)</span><br><span class="line">test_user_set = defaultdict(list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_cf</span><span class="params">(file_name)</span>:</span></span><br><span class="line">    inter_mat = list()</span><br><span class="line">    lines = open(file_name, <span class="string">"r"</span>).readlines()</span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> lines:</span><br><span class="line">        tmps = l.strip()</span><br><span class="line">        inters = [int(i) <span class="keyword">for</span> i <span class="keyword">in</span> tmps.split(<span class="string">" "</span>)]</span><br><span class="line"></span><br><span class="line">        u_id, pos_ids = inters[<span class="number">0</span>], inters[<span class="number">1</span>:]</span><br><span class="line">        pos_ids = list(set(pos_ids))</span><br><span class="line">        <span class="keyword">for</span> i_id <span class="keyword">in</span> pos_ids:</span><br><span class="line">            inter_mat.append([u_id, i_id])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.array(inter_mat)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remap_item</span><span class="params">(train_data, test_data)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> n_users, n_items</span><br><span class="line">    n_users = max(max(train_data[:, <span class="number">0</span>]), max(test_data[:, <span class="number">0</span>])) + <span class="number">1</span></span><br><span class="line">    n_items = max(max(train_data[:, <span class="number">1</span>]), max(test_data[:, <span class="number">1</span>])) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> u_id, i_id <span class="keyword">in</span> train_data:</span><br><span class="line">        train_user_set[int(u_id)].append(int(i_id))</span><br><span class="line">    <span class="keyword">for</span> u_id, i_id <span class="keyword">in</span> test_data:</span><br><span class="line">        test_user_set[int(u_id)].append(int(i_id))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_triplets</span><span class="params">(file_name)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> n_entities, n_relations, n_nodes</span><br><span class="line"></span><br><span class="line">    can_triplets_np = np.loadtxt(file_name, dtype=np.int32)</span><br><span class="line">    can_triplets_np = np.unique(can_triplets_np, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.inverse_r:</span><br><span class="line">        <span class="comment"># get triplets with inverse direction like &lt;entity, is-aspect-of, item&gt;</span></span><br><span class="line">        inv_triplets_np = can_triplets_np.copy()</span><br><span class="line">        inv_triplets_np[:, <span class="number">0</span>] = can_triplets_np[:, <span class="number">2</span>]</span><br><span class="line">        inv_triplets_np[:, <span class="number">2</span>] = can_triplets_np[:, <span class="number">0</span>]</span><br><span class="line">        inv_triplets_np[:, <span class="number">1</span>] = can_triplets_np[:, <span class="number">1</span>] + max(can_triplets_np[:, <span class="number">1</span>]) + <span class="number">1</span></span><br><span class="line">        <span class="comment"># consider two additional relations --- 'interact' and 'be interacted'</span></span><br><span class="line">        can_triplets_np[:, <span class="number">1</span>] = can_triplets_np[:, <span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">        inv_triplets_np[:, <span class="number">1</span>] = inv_triplets_np[:, <span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">        <span class="comment"># get full version of knowledge graph</span></span><br><span class="line">        triplets = np.concatenate((can_triplets_np, inv_triplets_np), axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># consider two additional relations --- 'interact'.</span></span><br><span class="line">        can_triplets_np[:, <span class="number">1</span>] = can_triplets_np[:, <span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">        triplets = can_triplets_np.copy()</span><br><span class="line"></span><br><span class="line">    n_entities = max(max(triplets[:, <span class="number">0</span>]), max(triplets[:, <span class="number">2</span>])) + <span class="number">1</span>  <span class="comment"># including items + users</span></span><br><span class="line">    n_nodes = n_entities + n_users</span><br><span class="line">    n_relations = max(triplets[:, <span class="number">1</span>]) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> triplets</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_graph</span><span class="params">(train_data, triplets)</span>:</span></span><br><span class="line">    ckg_graph = nx.MultiDi_init_weightGraph()</span><br><span class="line">    rd = defaultdict(list)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Begin to load interaction triples ..."</span>)</span><br><span class="line">    <span class="keyword">for</span> u_id, i_id <span class="keyword">in</span> tqdm(train_data, ascii=<span class="literal">True</span>):</span><br><span class="line">        rd[<span class="number">0</span>].append([u_id, i_id])</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"\nBegin to load kno_init_weightwledge graph triples ..."</span>)</span><br><span class="line">    <span class="keyword">for</span> h_id, r_id, t_id <span class="keyword">in</span> tqdm(triplets, ascii=<span class="literal">True</span>):</span><br><span class="line">        ckg_graph.add_edge(h_id, t_id, key=r_id)</span><br><span class="line">        rd[r_id].append([h_id, t_id])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ckg_graph, rd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_sparse_relational_graph</span><span class="params">(relation_dict)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_bi_norm_lap</span><span class="params">(adj)</span>:</span></span><br><span class="line">        <span class="comment"># D^&#123;-1/2&#125;AD^&#123;-1/2&#125;</span></span><br><span class="line">        rowsum = np.array(adj.sum(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        d_inv_sqrt = np.power(rowsum, <span class="number">-0.5</span>).flatten()</span><br><span class="line">        d_inv_sqrt[np.isinf(d_inv_sqrt)] = <span class="number">0.</span></span><br><span class="line">        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># bi_lap = adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt)</span></span><br><span class="line">        bi_lap = d_mat_inv_sqrt.dot(adj).dot(d_mat_inv_sqrt)</span><br><span class="line">        <span class="keyword">return</span> bi_lap.tocoo()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_si_norm_lap</span><span class="params">(adj)</span>:</span></span><br><span class="line">        <span class="comment"># D^&#123;-1&#125;A</span></span><br><span class="line">        rowsum = np.array(adj.sum(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        d_inv = np.power(rowsum, <span class="number">-1</span>).flatten()</span><br><span class="line">        d_inv[np.isinf(d_inv)] = <span class="number">0.</span></span><br><span class="line">        d_mat_inv = sp.diags(d_inv)</span><br><span class="line"></span><br><span class="line">        norm_adj = d_mat_inv.dot(adj)</span><br><span class="line">        <span class="keyword">return</span> norm_adj.tocoo()</span><br><span class="line"></span><br><span class="line">    adj_mat_list = []</span><br><span class="line">    print(<span class="string">"Begin to build sparse relation matrix ..."</span>)</span><br><span class="line">    <span class="keyword">for</span> r_id <span class="keyword">in</span> tqdm(relation_dict.keys()):</span><br><span class="line">        np_mat = np.array(relation_dict[r_id])</span><br><span class="line">        <span class="keyword">if</span> r_id == <span class="number">0</span>:</span><br><span class="line">            cf = np_mat.copy()</span><br><span class="line">            cf[:, <span class="number">1</span>] = cf[:, <span class="number">1</span>] + n_users  <span class="comment"># [0, n_items) -&gt; [n_users, n_users+n_items)</span></span><br><span class="line">            vals = [<span class="number">1.</span>] * len(cf)</span><br><span class="line">            adj = sp.coo_matrix((vals, (cf[:, <span class="number">0</span>], cf[:, <span class="number">1</span>])), shape=(n_nodes, n_nodes))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            vals = [<span class="number">1.</span>] * len(np_mat)</span><br><span class="line">            adj = sp.coo_matrix((vals, (np_mat[:, <span class="number">0</span>], np_mat[:, <span class="number">1</span>])), shape=(n_nodes, n_nodes))</span><br><span class="line">        adj_mat_list.append(adj)</span><br><span class="line"></span><br><span class="line">    norm_mat_list = [_bi_norm_lap(mat) <span class="keyword">for</span> mat <span class="keyword">in</span> adj_mat_list]</span><br><span class="line">    mean_mat_list = [_si_norm_lap(mat) <span class="keyword">for</span> mat <span class="keyword">in</span> adj_mat_list]</span><br><span class="line">    <span class="comment"># interaction: user-&gt;item, [n_users, n_entities]</span></span><br><span class="line">    norm_mat_list[<span class="number">0</span>] = norm_mat_list[<span class="number">0</span>].tocsr()[:n_users, n_users:].tocoo()</span><br><span class="line">    mean_mat_list[<span class="number">0</span>] = mean_mat_list[<span class="number">0</span>].tocsr()[:n_users, n_users:].tocoo()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> adj_mat_list, norm_mat_list, mean_mat_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(model_args)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> args</span><br><span class="line">    args = model_args</span><br><span class="line">    directory = args.data_path + args.dataset + <span class="string">'/'</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">'reading train and test user-item set ...'</span>)</span><br><span class="line">    train_cf = read_cf(directory + <span class="string">'train.txt'</span>)</span><br><span class="line">    test_cf = read_cf(directory + <span class="string">'test.txt'</span>)</span><br><span class="line">    remap_item(train_cf, test_cf)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'combinating train_cf and kg data ...'</span>)</span><br><span class="line">    triplets = read_triplets(directory + <span class="string">'kg_final.txt'</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'building the graph ...'</span>)</span><br><span class="line">    graph, relation_dict = build_graph(train_cf, triplets)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'building the adj mat ...'</span>)</span><br><span class="line">    adj_mat_list, norm_mat_list, mean_mat_list = build_sparse_relational_graph(relation_dict)</span><br><span class="line"></span><br><span class="line">    n_params = &#123;</span><br><span class="line">        <span class="string">'n_users'</span>: int(n_users),</span><br><span class="line">        <span class="string">'n_items'</span>: int(n_items),</span><br><span class="line">        <span class="string">'n_entities'</span>: int(n_entities),</span><br><span class="line">        <span class="string">'n_nodes'</span>: int(n_nodes),</span><br><span class="line">        <span class="string">'n_relations'</span>: int(n_relations)</span><br><span class="line">    &#125;</span><br><span class="line">    user_dict = &#123;</span><br><span class="line">        <span class="string">'train_user_set'</span>: train_user_set,</span><br><span class="line">        <span class="string">'test_user_set'</span>: test_user_set</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_cf, test_cf, user_dict, n_params, graph, \</span><br><span class="line">           [adj_mat_list, norm_mat_list, mean_mat_list]</span><br></pre></td></tr></table></figure>
<h1 id="evaluate-py"><a href="#evaluate-py" class="headerlink" title="evaluate.py"></a>evaluate.py</h1><p>模型测试代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> .metrics <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> .parser <span class="keyword">import</span> parse_args</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">cores = multiprocessing.cpu_count() // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">args = parse_args()</span><br><span class="line">Ks = eval(args.Ks)</span><br><span class="line">device = torch.device(<span class="string">"cuda:"</span> + str(args.gpu_id)) <span class="keyword">if</span> args.cuda <span class="keyword">else</span> torch.device(<span class="string">"cpu"</span>)</span><br><span class="line">BATCH_SIZE = args.test_batch_size</span><br><span class="line">batch_test_flag = args.batch_test_flag</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ranklist_by_heapq</span><span class="params">(user_pos_test, test_items, rating, Ks)</span>:</span></span><br><span class="line">    item_score = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> test_items:</span><br><span class="line">        item_score[i] = rating[i]</span><br><span class="line"></span><br><span class="line">    K_max = max(Ks)</span><br><span class="line">    K_max_item_score = heapq.nlargest(K_max, item_score, key=item_score.get)</span><br><span class="line"></span><br><span class="line">    r = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> K_max_item_score:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> user_pos_test:</span><br><span class="line">            r.append(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            r.append(<span class="number">0</span>)</span><br><span class="line">    auc = <span class="number">0.</span></span><br><span class="line">    <span class="keyword">return</span> r, auc</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_auc</span><span class="params">(item_score, user_pos_test)</span>:</span></span><br><span class="line">    item_score = sorted(item_score.items(), key=<span class="keyword">lambda</span> kv: kv[<span class="number">1</span>])</span><br><span class="line">    item_score.reverse()</span><br><span class="line">    item_sort = [x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> item_score]</span><br><span class="line">    posterior = [x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> item_score]</span><br><span class="line"></span><br><span class="line">    r = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> item_sort:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> user_pos_test:</span><br><span class="line">            r.append(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            r.append(<span class="number">0</span>)</span><br><span class="line">    auc = AUC(ground_truth=r, prediction=posterior)</span><br><span class="line">    <span class="keyword">return</span> auc</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ranklist_by_sorted</span><span class="params">(user_pos_test, test_items, rating, Ks)</span>:</span></span><br><span class="line">    item_score = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> test_items:</span><br><span class="line">        item_score[i] = rating[i]</span><br><span class="line"></span><br><span class="line">    K_max = max(Ks)</span><br><span class="line">    K_max_item_score = heapq.nlargest(K_max, item_score, key=item_score.get)</span><br><span class="line"></span><br><span class="line">    r = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> K_max_item_score:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> user_pos_test:</span><br><span class="line">            r.append(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            r.append(<span class="number">0</span>)</span><br><span class="line">    auc = get_auc(item_score, user_pos_test)</span><br><span class="line">    <span class="keyword">return</span> r, auc</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_performance</span><span class="params">(user_pos_test, r, auc, Ks)</span>:</span></span><br><span class="line">    precision, recall, ndcg, hit_ratio = [], [], [], []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> K <span class="keyword">in</span> Ks:</span><br><span class="line">        precision.append(precision_at_k(r, K))</span><br><span class="line">        recall.append(recall_at_k(r, K, len(user_pos_test)))</span><br><span class="line">        ndcg.append(ndcg_at_k(r, K, user_pos_test))</span><br><span class="line">        hit_ratio.append(hit_at_k(r, K))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'recall'</span>: np.array(recall), <span class="string">'precision'</span>: np.array(precision),</span><br><span class="line">            <span class="string">'ndcg'</span>: np.array(ndcg), <span class="string">'hit_ratio'</span>: np.array(hit_ratio), <span class="string">'auc'</span>: auc&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_one_user</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="comment"># user u's ratings for user u</span></span><br><span class="line">    rating = x[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># uid</span></span><br><span class="line">    u = x[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># user u's items in the training set</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        training_items = train_user_set[u]</span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        training_items = []</span><br><span class="line">    <span class="comment"># user u's items in the test set</span></span><br><span class="line">    user_pos_test = test_user_set[u]</span><br><span class="line"></span><br><span class="line">    all_items = set(range(<span class="number">0</span>, n_items))</span><br><span class="line"></span><br><span class="line">    test_items = list(all_items - set(training_items))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.test_flag == <span class="string">'part'</span>:</span><br><span class="line">        r, auc = ranklist_by_heapq(user_pos_test, test_items, rating, Ks)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        r, auc = ranklist_by_sorted(user_pos_test, test_items, rating, Ks)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> get_performance(user_pos_test, r, auc, Ks)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(model, user_dict, n_params)</span>:</span></span><br><span class="line">    result = &#123;<span class="string">'precision'</span>: np.zeros(len(Ks)),</span><br><span class="line">              <span class="string">'recall'</span>: np.zeros(len(Ks)),</span><br><span class="line">              <span class="string">'ndcg'</span>: np.zeros(len(Ks)),</span><br><span class="line">              <span class="string">'hit_ratio'</span>: np.zeros(len(Ks)),</span><br><span class="line">              <span class="string">'auc'</span>: <span class="number">0.</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">global</span> n_users, n_items</span><br><span class="line">    n_items = n_params[<span class="string">'n_items'</span>]</span><br><span class="line">    n_users = n_params[<span class="string">'n_users'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">global</span> train_user_set, test_user_set</span><br><span class="line">    train_user_set = user_dict[<span class="string">'train_user_set'</span>]</span><br><span class="line">    test_user_set = user_dict[<span class="string">'test_user_set'</span>]</span><br><span class="line"></span><br><span class="line">    pool = multiprocessing.Pool(cores)</span><br><span class="line"></span><br><span class="line">    u_batch_size = BATCH_SIZE</span><br><span class="line">    i_batch_size = BATCH_SIZE</span><br><span class="line"></span><br><span class="line">    test_users = list(test_user_set.keys())</span><br><span class="line">    n_test_users = len(test_users)</span><br><span class="line">    n_user_batchs = n_test_users // u_batch_size + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    entity_gcn_emb, user_gcn_emb = model.generate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> u_batch_id <span class="keyword">in</span> range(n_user_batchs):</span><br><span class="line">        start = u_batch_id * u_batch_size</span><br><span class="line">        end = (u_batch_id + <span class="number">1</span>) * u_batch_size</span><br><span class="line"></span><br><span class="line">        user_list_batch = test_users[start: end]</span><br><span class="line">        user_batch = torch.LongTensor(np.array(user_list_batch)).to(device)</span><br><span class="line">        u_g_embeddings = user_gcn_emb[user_batch]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> batch_test_flag:</span><br><span class="line">            <span class="comment"># batch-item test</span></span><br><span class="line">            n_item_batchs = n_items // i_batch_size + <span class="number">1</span></span><br><span class="line">            rate_batch = np.zeros(shape=(len(user_batch), n_items))</span><br><span class="line"></span><br><span class="line">            i_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> i_batch_id <span class="keyword">in</span> range(n_item_batchs):</span><br><span class="line">                i_start = i_batch_id * i_batch_size</span><br><span class="line">                i_end = min((i_batch_id + <span class="number">1</span>) * i_batch_size, n_items)</span><br><span class="line"></span><br><span class="line">                item_batch = torch.LongTensor(np.array(range(i_start, i_end))).view(i_end-i_start).to(device)</span><br><span class="line">                i_g_embddings = entity_gcn_emb[item_batch]</span><br><span class="line"></span><br><span class="line">                i_rate_batch = model.rating(u_g_embeddings, i_g_embddings).detach().cpu()</span><br><span class="line"></span><br><span class="line">                rate_batch[:, i_start: i_end] = i_rate_batch</span><br><span class="line">                i_count += i_rate_batch.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">assert</span> i_count == n_items</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># all-item test</span></span><br><span class="line">            item_batch = torch.LongTensor(np.array(range(<span class="number">0</span>, n_items))).view(n_items, <span class="number">-1</span>).to(device)</span><br><span class="line">            i_g_embddings = entity_gcn_emb[item_batch]</span><br><span class="line">            rate_batch = model.rating(u_g_embeddings, i_g_embddings).detach().cpu()</span><br><span class="line"></span><br><span class="line">        user_batch_rating_uid = zip(rate_batch, user_list_batch)</span><br><span class="line">        batch_result = pool.map(test_one_user, user_batch_rating_uid)</span><br><span class="line">        count += len(batch_result)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> re <span class="keyword">in</span> batch_result:</span><br><span class="line">            result[<span class="string">'precision'</span>] += re[<span class="string">'precision'</span>]/n_test_users</span><br><span class="line">            result[<span class="string">'recall'</span>] += re[<span class="string">'recall'</span>]/n_test_users</span><br><span class="line">            result[<span class="string">'ndcg'</span>] += re[<span class="string">'ndcg'</span>]/n_test_users</span><br><span class="line">            result[<span class="string">'hit_ratio'</span>] += re[<span class="string">'hit_ratio'</span>]/n_test_users</span><br><span class="line">            result[<span class="string">'auc'</span>] += re[<span class="string">'auc'</span>]/n_test_users</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> count == n_test_users</span><br><span class="line">    pool.close()</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<h1 id="helper-py"><a href="#helper-py" class="headerlink" title="helper.py"></a>helper.py</h1><p>一些辅助接口</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Created on Aug 19, 2016</span></span><br><span class="line"><span class="string">@author: Xiang Wang (xiangwang@u.nus.edu)</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">__author__ = <span class="string">"xiangwang"</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">txt2list</span><span class="params">(file_src)</span>:</span></span><br><span class="line">    orig_file = open(file_src, <span class="string">"r"</span>)</span><br><span class="line">    lines = orig_file.readlines()</span><br><span class="line">    <span class="keyword">return</span> lines</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ensureDir</span><span class="params">(dir_path)</span>:</span></span><br><span class="line">    d = os.path.dirname(dir_path)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(d):</span><br><span class="line">        os.makedirs(d)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">uni2str</span><span class="params">(unicode_str)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> str(unicode_str.encode(<span class="string">'ascii'</span>, <span class="string">'ignore'</span>)).replace(<span class="string">'\n'</span>, <span class="string">''</span>).strip()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hasNumbers</span><span class="params">(inputString)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> bool(re.search(<span class="string">r'\d'</span>, inputString))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">delMultiChar</span><span class="params">(inputString, chars)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> ch <span class="keyword">in</span> chars:</span><br><span class="line">        inputString = inputString.replace(ch, <span class="string">''</span>)</span><br><span class="line">    <span class="keyword">return</span> inputString</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge_two_dicts</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    z = x.copy()   <span class="comment"># start with x's keys and values</span></span><br><span class="line">    z.update(y)    <span class="comment"># modifies z with y's keys and values &amp; returns None</span></span><br><span class="line">    <span class="keyword">return</span> z</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">early_stopping</span><span class="params">(log_value, best_value, stopping_step, expected_order=<span class="string">'acc'</span>, flag_step=<span class="number">100</span>)</span>:</span></span><br><span class="line">    <span class="comment"># early stopping strategy:</span></span><br><span class="line">    <span class="keyword">assert</span> expected_order <span class="keyword">in</span> [<span class="string">'acc'</span>, <span class="string">'dec'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (expected_order == <span class="string">'acc'</span> <span class="keyword">and</span> log_value &gt;= best_value) <span class="keyword">or</span> (expected_order == <span class="string">'dec'</span> <span class="keyword">and</span> log_value &lt;= best_value):</span><br><span class="line">        stopping_step = <span class="number">0</span></span><br><span class="line">        best_value = log_value</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        stopping_step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> stopping_step &gt;= flag_step:</span><br><span class="line">        print(<span class="string">"Early stopping is trigger at step: &#123;&#125; log:&#123;&#125;"</span>.format(flag_step, log_value))</span><br><span class="line">        should_stop = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        should_stop = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> best_value, stopping_step, should_stop</span><br></pre></td></tr></table></figure>
<h1 id="metrics-py"><a href="#metrics-py" class="headerlink" title="metrics.py"></a>metrics.py</h1><p>实验用的评测指标，主要有：</p>
<ul>
<li>recall     召回率</li>
<li>precision_at_k    TopK精确率</li>
<li>average_precision    area under PR curve</li>
<li>ndcg@k</li>
</ul>
<p>……</p>
<ul>
<li>AUC</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">recall</span><span class="params">(rank, ground_truth, N)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> len(set(rank[:N]) &amp; set(ground_truth)) / float(len(set(ground_truth)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">precision_at_k</span><span class="params">(r, k)</span>:</span></span><br><span class="line">    <span class="string">"""Score is precision @ k</span></span><br><span class="line"><span class="string">    Relevance is binary (nonzero is relevant).</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        Precision @ k</span></span><br><span class="line"><span class="string">    Raises:</span></span><br><span class="line"><span class="string">        ValueError: len(r) must be &gt;= k</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">assert</span> k &gt;= <span class="number">1</span></span><br><span class="line">    r = np.asarray(r)[:k]</span><br><span class="line">    <span class="keyword">return</span> np.mean(r)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">average_precision</span><span class="params">(r,cut)</span>:</span></span><br><span class="line">    <span class="string">"""Score is average precision (area under PR curve)</span></span><br><span class="line"><span class="string">    Relevance is binary (nonzero is relevant).</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        Average precision</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    r = np.asarray(r)</span><br><span class="line">    out = [precision_at_k(r, k + <span class="number">1</span>) <span class="keyword">for</span> k <span class="keyword">in</span> range(cut) <span class="keyword">if</span> r[k]]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> out:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.</span></span><br><span class="line">    <span class="keyword">return</span> np.sum(out)/float(min(cut, np.sum(r)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mean_average_precision</span><span class="params">(rs)</span>:</span></span><br><span class="line">    <span class="string">"""Score is mean average precision</span></span><br><span class="line"><span class="string">    Relevance is binary (nonzero is relevant).</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        Mean average precision</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> np.mean([average_precision(r) <span class="keyword">for</span> r <span class="keyword">in</span> rs])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dcg_at_k</span><span class="params">(r, k, method=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Score is discounted cumulative gain (dcg)</span></span><br><span class="line"><span class="string">    Relevance is positive real values.  Can use binary</span></span><br><span class="line"><span class="string">    as the previous methods.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        Discounted cumulative gain</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    r = np.asfarray(r)[:k]</span><br><span class="line">    <span class="keyword">if</span> r.size:</span><br><span class="line">        <span class="keyword">if</span> method == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> r[<span class="number">0</span>] + np.sum(r[<span class="number">1</span>:] / np.log2(np.arange(<span class="number">2</span>, r.size + <span class="number">1</span>)))</span><br><span class="line">        <span class="keyword">elif</span> method == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> np.sum(r / np.log2(np.arange(<span class="number">2</span>, r.size + <span class="number">2</span>)))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'method must be 0 or 1.'</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ndcg_at_k</span><span class="params">(r, k, ground_truth, method=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Score is normalized discounted cumulative gain (ndcg)</span></span><br><span class="line"><span class="string">    Relevance is positive real values.  Can use binary</span></span><br><span class="line"><span class="string">    as the previous methods.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        Normalized discounted cumulative gain</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Low but correct defination</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    GT = set(ground_truth)</span><br><span class="line">    <span class="keyword">if</span> len(GT) &gt; k :</span><br><span class="line">        sent_list = [<span class="number">1.0</span>] * k</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        sent_list = [<span class="number">1.0</span>]*len(GT) + [<span class="number">0.0</span>]*(k-len(GT))</span><br><span class="line">    dcg_max = dcg_at_k(sent_list, k, method)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> dcg_max:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.</span></span><br><span class="line">    <span class="keyword">return</span> dcg_at_k(r, k, method) / dcg_max</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">recall_at_k</span><span class="params">(r, k, all_pos_num)</span>:</span></span><br><span class="line">    r = np.asfarray(r)[:k]</span><br><span class="line">    <span class="keyword">return</span> np.sum(r) / all_pos_num</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hit_at_k</span><span class="params">(r, k)</span>:</span></span><br><span class="line">    r = np.array(r)[:k]</span><br><span class="line">    <span class="keyword">if</span> np.sum(r) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">F1</span><span class="params">(pre, rec)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> pre + rec &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">2.0</span> * pre * rec) / (pre + rec)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">AUC</span><span class="params">(ground_truth, prediction)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = roc_auc_score(y_true=ground_truth, y_score=prediction)</span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        res = <span class="number">0.</span></span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h1 id="parser-py"><a href="#parser-py" class="headerlink" title="parser.py"></a>parser.py</h1><p>该文件比较简单，负责读取命令行输入的训练参数、默认训练参数设置以及参数注释。调用的核心接口是<code>argparse.ArgumentParser.add_argument</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_args</span><span class="params">()</span>:</span></span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">"KGIN"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ===== dataset ===== #</span></span><br><span class="line">    parser.add_argument(<span class="string">"--dataset"</span>, nargs=<span class="string">"?"</span>, default=<span class="string">"last-fm"</span>, help=<span class="string">"Choose a dataset:[last-fm,amazon-book,alibaba]"</span>)</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">"--data_path"</span>, nargs=<span class="string">"?"</span>, default=<span class="string">"data/"</span>, help=<span class="string">"Input data path."</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ===== train ===== #</span></span><br><span class="line">    parser.add_argument(<span class="string">'--epoch'</span>, type=int, default=<span class="number">1000</span>, help=<span class="string">'number of epochs'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--batch_size'</span>, type=int, default=<span class="number">1024</span>, help=<span class="string">'batch size'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--test_batch_size'</span>, type=int, default=<span class="number">1024</span>, help=<span class="string">'batch size'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--dim'</span>, type=int, default=<span class="number">64</span>, help=<span class="string">'embedding size'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--l2'</span>, type=float, default=<span class="number">1e-5</span>, help=<span class="string">'l2 regularization weight'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--lr'</span>, type=float, default=<span class="number">1e-4</span>, help=<span class="string">'learning rate'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--sim_regularity'</span>, type=float, default=<span class="number">1e-4</span>, help=<span class="string">'regularization weight for latent factor'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--inverse_r"</span>, type=bool, default=<span class="literal">True</span>, help=<span class="string">"consider inverse relation or not"</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--node_dropout"</span>, type=bool, default=<span class="literal">True</span>, help=<span class="string">"consider node dropout or not"</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--node_dropout_rate"</span>, type=float, default=<span class="number">0.5</span>, help=<span class="string">"ratio of node dropout"</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--mess_dropout"</span>, type=bool, default=<span class="literal">True</span>, help=<span class="string">"consider message dropout or not"</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--mess_dropout_rate"</span>, type=float, default=<span class="number">0.1</span>, help=<span class="string">"ratio of node dropout"</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--batch_test_flag"</span>, type=bool, default=<span class="literal">True</span>, help=<span class="string">"use gpu or not"</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--channel"</span>, type=int, default=<span class="number">64</span>, help=<span class="string">"hidden channels for model"</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--cuda"</span>, type=bool, default=<span class="literal">True</span>, help=<span class="string">"use gpu or not"</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--gpu_id"</span>, type=int, default=<span class="number">0</span>, help=<span class="string">"gpu id"</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--Ks'</span>, nargs=<span class="string">'?'</span>, default=<span class="string">'[20, 40, 60, 80, 100]'</span>, help=<span class="string">'Output sizes of every layer'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--test_flag'</span>, nargs=<span class="string">'?'</span>, default=<span class="string">'part'</span>,</span><br><span class="line">                        help=<span class="string">'Specify the test type from &#123;part, full&#125;, indicating whether the reference is done in mini-batch'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--n_factors"</span>, type=int, default=   <span class="number">4</span>, help=<span class="string">"number of latent factor for user favour"</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--ind"</span>, type=str, default=<span class="string">'distance'</span>, help=<span class="string">"Independence modeling: mi, distance, cosine"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ===== relation context ===== #</span></span><br><span class="line">    parser.add_argument(<span class="string">'--context_hops'</span>, type=int, default=<span class="number">3</span>, help=<span class="string">'number of context hops'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ===== save model ===== #</span></span><br><span class="line">    parser.add_argument(<span class="string">"--save"</span>, type=bool, default=<span class="literal">False</span>, help=<span class="string">"save model or not"</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--out_dir"</span>, type=str, default=<span class="string">"./weights/"</span>, help=<span class="string">"output directory for model"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parser.parse_args()</span><br></pre></td></tr></table></figure>
<h1 id="KGIN-py"><a href="#KGIN-py" class="headerlink" title="KGIN.py"></a>KGIN.py</h1><h2 id="Relational-Path-aware-Aggregation"><a href="#Relational-Path-aware-Aggregation" class="headerlink" title="Relational Path-aware Aggregation"></a>Relational Path-aware Aggregation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Created on July 1, 2020</span></span><br><span class="line"><span class="string">PyTorch Implementation of KGIN</span></span><br><span class="line"><span class="string">@author: Tinglin Huang (tinglin.huang@zju.edu.cn)</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">__author__ = <span class="string">"huangtinglin"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch_scatter <span class="keyword">import</span> scatter_mean</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Aggregator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Relational Path-aware Convolution Network</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_users, n_factors)</span>:</span></span><br><span class="line">        super(Aggregator, self).__init__()</span><br><span class="line">        self.n_users = n_users</span><br><span class="line">        self.n_factors = n_factors</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, entity_emb, user_emb, latent_emb,</span></span></span><br><span class="line"><span class="function"><span class="params">                edge_index, edge_type, interact_mat,</span></span></span><br><span class="line"><span class="function"><span class="params">                weight, disen_weight_att)</span>:</span></span><br><span class="line"></span><br><span class="line">        n_entities = entity_emb.shape[<span class="number">0</span>]</span><br><span class="line">        channel = entity_emb.shape[<span class="number">1</span>]<span class="comment">#embedding size,dim</span></span><br><span class="line">        </span><br><span class="line">        n_users = self.n_users</span><br><span class="line">        n_factors = self.n_factors<span class="comment"># 用户偏好的隐因子 默认值为4</span></span><br></pre></td></tr></table></figure>
<h4 id="3-2-2-Aggregation-Layer-over-Knowledge-Graph"><a href="#3-2-2-Aggregation-Layer-over-Knowledge-Graph" class="headerlink" title="3.2.2 Aggregation Layer over Knowledge Graph"></a>3.2.2 Aggregation Layer over Knowledge Graph</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""KG aggregate"""</span></span><br><span class="line">head, tail = edge_index</span><br><span class="line">edge_relation_emb = weight[edge_type - <span class="number">1</span>]  <span class="comment"># exclude interact, remap [1, n_relations) to [0, n_relations-1)</span></span><br><span class="line"><span class="comment">#weight形状是[n_relations - 1, in_channel=arg.dim]，表示各个关系的嵌入表示</span></span><br><span class="line"><span class="comment">#edge_relation_emb 通过 edge_type - 1 取出 edge_type对应relation的嵌入表示</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tail=edge_index[1],shape=[tripletsNum,]</span></span><br><span class="line"><span class="comment"># entity_emb[tail].shape=[tripletsNum,embSize]</span></span><br><span class="line"><span class="comment"># edge_relation_emb.shape=[tripletsNum,embSize]</span></span><br><span class="line">neigh_relation_emb = entity_emb[tail] * edge_relation_emb  <span class="comment"># [-1, channel]</span></span><br></pre></td></tr></table></figure>
<p>对于KG中的实体结点$i$，嵌入表示为$e_{i}$，由其邻居结点聚合得到，公式如(1)所示</p>
<script type="math/tex; mode=display">
e_{i}^{(1)}=\frac{1}{|N_{i}|}\sum_{(r,v)\in N_{i}}e_{r}\odot e_{v}^{(0)}</script><p>其中<script type="math/tex">\odot</script>是element-wise product，即逐元素乘法</p>
<p>给出该公式的示意图辅助理解：</p>
<p><img src="/2021/11/10/Knowledge-Graph-based-Intent-Network-Code-Read/毕业设计\img\nodeInKGEmbedding.png" alt="nodeInKGEmbedding"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">entity_agg = scatter_mean(src=neigh_relation_emb, index=head, dim_size=n_entities, dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>scatter_mean操作示意图如下：</p>
<p><img src="/2021/11/10/Knowledge-Graph-based-Intent-Network-Code-Read/毕业设计\img\scatter_mean.png" alt><br>具体到此处，scatter_mean的作用是将形状为[tripletsNum,embSize]的<code>neigh_relation_emb</code>的行向量，根据传入的head，分发到对应head的位置上求均值。可以理解为<code>neigh_relation_emb</code>是$e_{r}\odot e_{v}^{(0)}$的结算结果，而求均值由scatter_mean完成。示意图如下：<br><img src="/2021/11/10/Knowledge-Graph-based-Intent-Network-Code-Read/毕业设计\img\AggregationLayerOverKG.png" alt></p>
<h4 id="3-2-1-Aggregation-Layer-over-Intent-Graph"><a href="#3-2-1-Aggregation-Layer-over-Intent-Graph" class="headerlink" title="3.2.1 Aggregation Layer over Intent Graph."></a>3.2.1 Aggregation Layer over Intent Graph.</h4><p>注意力机制，计算隐因子（用户意图向量）和用户嵌入表示的注意力分数</p>
<script type="math/tex; mode=display">
\beta(u,p)=\frac{exp(e_{p}^{T}e_{u}^{(0)})}{\sum_{p^{\prime}\in P}exp(e_{p^{\prime}}^{T}e_{u}^{(0)})}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""cul user-&gt;latent factor attention"""</span></span><br><span class="line">score_ = torch.mm(user_emb, latent_emb.t())</span><br><span class="line">score = nn.Softmax(dim=<span class="number">1</span>)(score_).unsqueeze(<span class="number">-1</span>)  <span class="comment"># [n_users, n_factors, 1]</span></span><br></pre></td></tr></table></figure>
<p>用户向量计算：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""user aggregate"""</span></span><br><span class="line">user_agg = torch.sparse.mm(interact_mat, entity_emb)  <span class="comment"># [n_users, channel]</span></span><br><span class="line"><span class="comment">#[n_users,n_entity] \cdot [n_entity,channel=embd_size]=&gt;[n_users, channel]</span></span><br></pre></td></tr></table></figure>
<p>交互矩阵interact_mat是拉普拉斯矩阵，则此处计算的是</p>
<script type="math/tex; mode=display">
user\_agg[u_{i}]=\sum_{i \in interaction(u,i)}{L(u,i)*e_{i}}\\
\large e_{u_{}}^{(1)}=\sum_{i \in interaction(u)}{L(u,i)*e_{i}^{(0)}}\\
usrEmbMat=LaplacianMat \cdot itemEmbedMat</script><p>相当于用用户的行为历史（交互过的物品/实体）向量做一个聚合表示。</p>
<p>disen_weight_att被定义在GraphConv的<code>__init__</code>方法中，<code>disen_weight_att = initializer(torch.empty(n_factors, n_relations - 1))</code>,表示隐因子（用户意图）与KG中各个relation的关系（从shape和注释来看不包含user-item-interaction）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">disen_weight = torch.mm(nn.Softmax(dim=<span class="number">-1</span>)(disen_weight_att),weight)</span><br><span class="line">		.expand(n_users, n_factors, channel)</span><br></pre></td></tr></table></figure>
<p><code>nn.Softmax(dim=-1)(disen_weight_att)</code>计算用户意图$p_{i}$与各个relation的分数，shape为[n_factors, n_relations - 1]</p>
<p>weight是relation的嵌入矩阵，形状为[n_relations - 1, in_channel=arg.dim]</p>
<p>torch.mm()计算后形状为[n_factors, channel=arg.dim]</p>
<p>expand拷贝[n_factors, channel=arg.dim]向量广播成[n_users, n_factors, channel]形状。这个操作可行的原因是论文中提到过意图向量集合P被所有用户共享，视为<strong>所有用户都有的意图</strong>。但是每个意图与用户的契合度/信息量是通过注意力机制控制的。</p>
<p>上述计算过程等价于使用KG中的relation聚合表示意图向量</p>
<script type="math/tex; mode=display">
\large e_{p_{i}}=\sum att\_score_{p_{i},r_{j}}*e_{r_{j}}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">user_agg = user_agg * (disen_weight * score).sum(dim=<span class="number">1</span>) + user_agg  <span class="comment"># [n_users, channel]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> entity_agg, user_agg</span><br></pre></td></tr></table></figure>
<p><code>user_agg = user_agg * (disen_weight * score).sum(dim=1) + user_agg</code></p>
<p><code>(disen_weight * score)</code>：[n_users, n_factors, channel] * [n_users, n_factors, 1]=&gt;[n_users, n_factors, channel]</p>
<p>求解的是$\beta(u,p)e_{p}$，每个用户的每个意图向量乘上对应的注意力分数$\beta(u,p)$</p>
<p><code>(disen_weight * score).sum(dim=1)</code>：$\sum_{p}\beta(u,p)e_{p}$</p>
<p><code>user_agg * (disen_weight * score).sum(dim=1)</code>：</p>
<script type="math/tex; mode=display">
\sum_{i \in interaction(u,i)}{L(u,i)*e_{i}}*\sum_{p}\beta(u,p)e_{p}</script><p>对应于原论文中的公式(7)的一部分</p>
<script type="math/tex; mode=display">
e_{u}^{(1)}=\frac{1}{|N_{u}|}\sum_{(p,i)\in N_{u}}\beta(u,p)e_{p}\odot e_{i}^{(0)}</script><h2 id="图卷积网络"><a href="#图卷积网络" class="headerlink" title="图卷积网络"></a>图卷积网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GraphConv</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Graph Convolutional Network</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, channel, n_hops, n_users,</span></span></span><br><span class="line"><span class="function"><span class="params">                 n_factors, n_relations, interact_mat,</span></span></span><br><span class="line"><span class="function"><span class="params">                 ind, node_dropout_rate=<span class="number">0.5</span>, mess_dropout_rate=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        super(GraphConv, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.convs = nn.ModuleList()</span><br><span class="line">        self.interact_mat = interact_mat</span><br><span class="line">        self.n_relations = n_relations</span><br><span class="line">        self.n_users = n_users</span><br><span class="line">        self.n_factors = n_factors</span><br><span class="line">        self.node_dropout_rate = node_dropout_rate</span><br><span class="line">        self.mess_dropout_rate = mess_dropout_rate</span><br><span class="line">        self.ind = ind<span class="comment"># 衡量向量信息量相同程度的策略：互信息，距离，相关性</span></span><br><span class="line"></span><br><span class="line">        self.temperature = <span class="number">0.2</span></span><br><span class="line"></span><br><span class="line">        initializer = nn.init.xavier_uniform_</span><br><span class="line">        weight = initializer(torch.empty(n_relations - <span class="number">1</span>, channel))  <span class="comment"># not include interact</span></span><br><span class="line">        <span class="comment">#channel：hidden channels for model，channel的含义需要回顾论文,但其实际值为输入参数中的embedding size 即 dim参数</span></span><br><span class="line">        </span><br><span class="line">        self.weight = nn.Parameter(weight)  <span class="comment"># [n_relations - 1, in_channel]</span></span><br><span class="line">		<span class="comment"># weight矩阵是 KG中的relation的嵌入表示</span></span><br><span class="line">        </span><br><span class="line">        disen_weight_att = initializer(torch.empty(n_factors, n_relations - <span class="number">1</span>))</span><br><span class="line">        self.disen_weight_att = nn.Parameter(disen_weight_att)</span><br><span class="line">		<span class="comment">#disen_weight_att [n_factors, n_relations - 1]</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n_hops):</span><br><span class="line">            self.convs.append(Aggregator(n_users=n_users, n_factors=n_factors))</span><br><span class="line"></span><br><span class="line">        self.dropout = nn.Dropout(p=mess_dropout_rate)  <span class="comment"># mess dropout</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_edge_sampling</span><span class="params">(self, edge_index, edge_type, rate=<span class="number">0.5</span>)</span>:</span></span><br><span class="line">        <span class="comment"># edge_index: [2, -1]</span></span><br><span class="line">        <span class="comment"># edge_type: [-1]</span></span><br><span class="line">        n_edges = edge_index.shape[<span class="number">1</span>]</span><br><span class="line">        random_indices = np.random.choice(n_edges, size=int(n_edges * rate), replace=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">return</span> edge_index[:, random_indices], edge_type[random_indices]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_sparse_dropout</span><span class="params">(self, x, rate=<span class="number">0.5</span>)</span>:</span></span><br><span class="line">        noise_shape = x._nnz()</span><br><span class="line"></span><br><span class="line">        random_tensor = rate</span><br><span class="line">        random_tensor += torch.rand(noise_shape).to(x.device)</span><br><span class="line">        dropout_mask = torch.floor(random_tensor).type(torch.bool)</span><br><span class="line">        i = x._indices()</span><br><span class="line">        v = x._values()</span><br><span class="line"></span><br><span class="line">        i = i[:, dropout_mask]</span><br><span class="line">        v = v[dropout_mask]</span><br><span class="line"></span><br><span class="line">        out = torch.sparse.FloatTensor(i, v, x.shape).to(x.device)</span><br><span class="line">        <span class="keyword">return</span> out * (<span class="number">1.</span> / (<span class="number">1</span> - rate))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># def _cul_cor_pro(self):</span></span><br><span class="line">    <span class="comment">#     # disen_T: [num_factor, dimension]</span></span><br><span class="line">    <span class="comment">#     disen_T = self.disen_weight_att.t()</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#     # normalized_disen_T: [num_factor, dimension]</span></span><br><span class="line">    <span class="comment">#     normalized_disen_T = disen_T / disen_T.norm(dim=1, keepdim=True)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#     pos_scores = torch.sum(normalized_disen_T * normalized_disen_T, dim=1)</span></span><br><span class="line">    <span class="comment">#     ttl_scores = torch.sum(torch.mm(disen_T, self.disen_weight_att), dim=1)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#     pos_scores = torch.exp(pos_scores / self.temperature)</span></span><br><span class="line">    <span class="comment">#     ttl_scores = torch.exp(ttl_scores / self.temperature)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#     mi_score = - torch.sum(torch.log(pos_scores / ttl_scores))</span></span><br><span class="line">    <span class="comment">#     return mi_score</span></span><br></pre></td></tr></table></figure>
<h3 id="衡量向量间信息量相同程度"><a href="#衡量向量间信息量相同程度" class="headerlink" title="衡量向量间信息量相同程度"></a>衡量向量间信息量相同程度</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_cul_cor</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">CosineSimilarity</span><span class="params">(tensor_1, tensor_2)</span>:</span></span><br><span class="line">        <span class="comment"># tensor_1, tensor_2: [channel]</span></span><br><span class="line">        normalized_tensor_1 = tensor_1 / tensor_1.norm(dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        normalized_tensor_2 = tensor_2 / tensor_2.norm(dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> (normalized_tensor_1 * normalized_tensor_2).sum(dim=<span class="number">0</span>) ** <span class="number">2</span>  <span class="comment"># no negative</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">DistanceCorrelation</span><span class="params">(tensor_1, tensor_2)</span>:</span></span><br><span class="line">        <span class="comment"># tensor_1, tensor_2: [channel]</span></span><br><span class="line">        <span class="comment"># ref: https://en.wikipedia.org/wiki/Distance_correlation</span></span><br><span class="line">        channel = tensor_1.shape[<span class="number">0</span>]</span><br><span class="line">        zeros = torch.zeros(channel, channel).to(tensor_1.device)</span><br><span class="line">        zero = torch.zeros(<span class="number">1</span>).to(tensor_1.device)</span><br><span class="line">        tensor_1, tensor_2 = tensor_1.unsqueeze(<span class="number">-1</span>), tensor_2.unsqueeze(<span class="number">-1</span>)</span><br><span class="line">        <span class="string">"""cul distance matrix"""</span></span><br><span class="line">        a_, b_ = torch.matmul(tensor_1, tensor_1.t()) * <span class="number">2</span>, \</span><br><span class="line">               torch.matmul(tensor_2, tensor_2.t()) * <span class="number">2</span>  <span class="comment"># [channel, channel]</span></span><br><span class="line">        tensor_1_square, tensor_2_square = tensor_1 ** <span class="number">2</span>, tensor_2 ** <span class="number">2</span></span><br><span class="line">        a, b = torch.sqrt(torch.max(tensor_1_square - a_ + tensor_1_square.t(), zeros) + <span class="number">1e-8</span>), \</span><br><span class="line">               torch.sqrt(torch.max(tensor_2_square - b_ + tensor_2_square.t(), zeros) + <span class="number">1e-8</span>)  <span class="comment"># [channel, channel]</span></span><br><span class="line">        <span class="string">"""cul distance correlation"""</span></span><br><span class="line">        A = a - a.mean(dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>) - a.mean(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>) + a.mean()</span><br><span class="line">        B = b - b.mean(dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>) - b.mean(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>) + b.mean()</span><br><span class="line">        dcov_AB = torch.sqrt(torch.max((A * B).sum() / channel ** <span class="number">2</span>, zero) + <span class="number">1e-8</span>)</span><br><span class="line">        dcov_AA = torch.sqrt(torch.max((A * A).sum() / channel ** <span class="number">2</span>, zero) + <span class="number">1e-8</span>)</span><br><span class="line">        dcov_BB = torch.sqrt(torch.max((B * B).sum() / channel ** <span class="number">2</span>, zero) + <span class="number">1e-8</span>)</span><br><span class="line">        <span class="keyword">return</span> dcov_AB / torch.sqrt(dcov_AA * dcov_BB + <span class="number">1e-8</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">MutualInformation</span><span class="params">()</span>:</span></span><br><span class="line">        <span class="comment"># disen_T: [num_factor, dimension]</span></span><br><span class="line">        disen_T = self.disen_weight_att.t()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># normalized_disen_T: [num_factor, dimension]</span></span><br><span class="line">        normalized_disen_T = disen_T / disen_T.norm(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        pos_scores = torch.sum(normalized_disen_T * normalized_disen_T, dim=<span class="number">1</span>)</span><br><span class="line">        ttl_scores = torch.sum(torch.mm(disen_T, self.disen_weight_att), dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        pos_scores = torch.exp(pos_scores / self.temperature)</span><br><span class="line">        ttl_scores = torch.exp(ttl_scores / self.temperature)</span><br><span class="line"></span><br><span class="line">        mi_score = - torch.sum(torch.log(pos_scores / ttl_scores))</span><br><span class="line">        <span class="keyword">return</span> mi_score</span><br><span class="line"></span><br><span class="line">    <span class="string">"""cul similarity for each latent factor weight pairs"""</span></span><br><span class="line">    <span class="keyword">if</span> self.ind == <span class="string">'mi'</span>:</span><br><span class="line">        <span class="keyword">return</span> MutualInformation()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        cor = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n_factors):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, self.n_factors):</span><br><span class="line">                <span class="keyword">if</span> self.ind == <span class="string">'distance'</span>:</span><br><span class="line">                    cor += DistanceCorrelation(self.disen_weight_att[i], self.disen_weight_att[j])</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    cor += CosineSimilarity(self.disen_weight_att[i], self.disen_weight_att[j])</span><br><span class="line">    <span class="keyword">return</span> cor</span><br></pre></td></tr></table></figure>
<h3 id="图卷积网络前向计算"><a href="#图卷积网络前向计算" class="headerlink" title="图卷积网络前向计算"></a>图卷积网络前向计算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, user_emb, entity_emb, latent_emb, edge_index, edge_type,</span></span></span><br><span class="line"><span class="function"><span class="params">            interact_mat, mess_dropout=True, node_dropout=False)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""node dropout"""</span></span><br><span class="line">    <span class="keyword">if</span> node_dropout:</span><br><span class="line">        edge_index, edge_type = self._edge_sampling(edge_index, edge_type, self.node_dropout_rate)</span><br><span class="line">        interact_mat = self._sparse_dropout(interact_mat, self.node_dropout_rate)</span><br><span class="line"></span><br><span class="line">    entity_res_emb = entity_emb  <span class="comment"># [n_entity, channel]</span></span><br><span class="line">    user_res_emb = user_emb  <span class="comment"># [n_users, channel]</span></span><br><span class="line">    cor = self._cul_cor()</span><br></pre></td></tr></table></figure>
<p>Capturing Relational Paths两公式等价证明</p>
<script type="math/tex; mode=display">
\Large e_{i}^{(l)}=\frac{1}{|N_{i}|}\sum_{(r,v)\in N_{i}}{e_{r} \odot e_{v}^{(l-1)}}\\
\Large=\sum_{(r,v)\in N_{i}}{\frac{e_{r}}{|N_{i}|} \odot e_{v}^{(l-1)}}</script><p>为了方便，改变一些符号的记法</p>
<script type="math/tex; mode=display">
\Large e_{s_{0}}^{(l)}=\sum_{(r_{1},s_{1})\in N_{s_{0}}}{\frac{e_{r_{1}}}{|N_{s_{0}}|} \odot e_{s_{1}}^{(l-1)}}\\
\Large e_{s_{1}}^{(l-1)}=\sum_{(r_{2},s_{2})\in N_{s_{1}}}{\frac{e_{r_{2}}}{|N_{s_{1}}|} \odot e_{s_{2}}^{(l-2)}}\\
...\\
...\\
...\\
\Large e_{s_{l-1}}^{(1)}=\sum_{(r_{l},s_{l})\in N_{s_{l-1}}}{\frac{e_{r_{l}}}{|N_{s_{l-1}}|} \odot e_{s_{l}}^{(0)}}\\</script><p>综合可得：</p>
<script type="math/tex; mode=display">
\Large e_{s_{0}}^{(l)}=\sum_{(r_{1},s_{1})\in N_{s_{0}}}{\frac{e_{r_{1}}}{|N_{s_{0}}|} \odot (\sum_{(r_{2},s_{2})\in N_{s_{1}}}{\frac{e_{r_{2}}}{|N_{s_{1}}|} \odot e_{s_{2}}^{(l-2)}})}\\</script><script type="math/tex; mode=display">
\Large e_{s_{0}}^{(l)}=\sum_{(r_{1},s_{1})\in N_{s_{0}}}{\frac{e_{r_{1}}}{|N_{s_{0}}|} \odot (\sum_{(r_{2},s_{2})\in N_{s_{1}}}{\frac{e_{r_{2}}}{|N_{s_{1}}|} \odot (...(\sum_{(r_{l},s_{l})\in N_{s_{l-1}}}{\frac{e_{r_{l}}}{|N_{s_{l-1}}|} \odot e_{s_{l}}^{(0)}})...)})}\\</script><script type="math/tex; mode=display">
\Large e_{s_{0}}^{(l)}=\sum_{(r_{1},s_{1})\in N_{s_{0}}}{\sum_{(r_{2},s_{2})\in N_{s_{1}}}...\sum_{(r_{l},s_{l})\in N_{s_{l-1}}}\frac{e_{r_{1}}}{|N_{s_{0}}|} \odot {\frac{e_{r_{2}}}{|N_{s_{1}}|} \odot ... \odot \frac{e_{r_{l}}}{|N_{s_{l-1}}|} \odot e_{s_{l}}^{(0)}}}\\</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#KG上基于结点的多跳传播</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.convs)):</span><br><span class="line">    <span class="comment">#entity_emb，user_emb更新，具体更新过程公式在论文中的Aggregation Layer over Intent Graph和Aggregation Layer over Knowledge Graph， Capturing Relational Paths.即上面锁分析的Aggregation层的前向计算过程</span></span><br><span class="line">    entity_emb, user_emb = self.convs[i](entity_emb, user_emb, latent_emb,</span><br><span class="line">                                         edge_index, edge_type, interact_mat,</span><br><span class="line">                                         self.weight, self.disen_weight_att)</span><br><span class="line"></span><br><span class="line">    <span class="string">"""message dropout"""</span></span><br><span class="line">    <span class="keyword">if</span> mess_dropout:</span><br><span class="line">        entity_emb = self.dropout(entity_emb)</span><br><span class="line">        user_emb = self.dropout(user_emb)</span><br><span class="line">        </span><br><span class="line">    entity_emb = F.normalize(entity_emb)</span><br><span class="line">    user_emb = F.normalize(user_emb)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""result emb"""</span></span><br><span class="line">entity_res_emb = torch.add(entity_res_emb, entity_emb)</span><br><span class="line">user_res_emb = torch.add(user_res_emb, user_emb)</span><br></pre></td></tr></table></figure>
<p>这里对应论文中的公式13</p>
<script type="math/tex; mode=display">
e_{u}^{*}=e_{u}^{(0)}+...+e_{u}^{(L)}\\
e_{i}^{*}=e_{i}^{(0)}+...+e_{i}^{(L)}\\</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> entity_res_emb, user_res_emb, cor</span><br></pre></td></tr></table></figure>
<h2 id="推荐模型"><a href="#推荐模型" class="headerlink" title="推荐模型"></a>推荐模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Recommender</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data_config, args_config, graph, adj_mat)</span>:</span></span><br><span class="line">        super(Recommender, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.n_users = data_config[<span class="string">'n_users'</span>]<span class="comment">#用户数</span></span><br><span class="line">        self.n_items = data_config[<span class="string">'n_items'</span>]<span class="comment">#物品数</span></span><br><span class="line">        self.n_relations = data_config[<span class="string">'n_relations'</span>]<span class="comment">#关系总数=usritm_interaction+KG rel</span></span><br><span class="line">        self.n_entities = data_config[<span class="string">'n_entities'</span>]  <span class="comment"># include items</span></span><br><span class="line">        self.n_nodes = data_config[<span class="string">'n_nodes'</span>]  <span class="comment"># n_users + n_entities</span></span><br><span class="line"></span><br><span class="line">        self.decay = args_config.l2<span class="comment">#L2 正则权重</span></span><br><span class="line">        self.sim_decay = args_config.sim_regularity<span class="comment"># 隐因子的正则化权重</span></span><br><span class="line">        self.emb_size = args_config.dim<span class="comment">#嵌入向量维度</span></span><br><span class="line">        self.context_hops = args_config.context_hops<span class="comment">#关系上下文的最大跳数</span></span><br><span class="line">        self.n_factors = args_config.n_factors<span class="comment">#用户偏好的隐因子数目</span></span><br><span class="line">        self.node_dropout = args_config.node_dropout<span class="comment">#bool：结点裁剪控制</span></span><br><span class="line">        self.node_dropout_rate = args_config.node_dropout_rate<span class="comment">#结点裁剪率</span></span><br><span class="line">        self.mess_dropout = args_config.mess_dropout<span class="comment">#消息裁剪控制</span></span><br><span class="line">        self.mess_dropout_rate = args_config.mess_dropout_rate<span class="comment">#消息裁剪率</span></span><br><span class="line">        self.ind = args_config.ind<span class="comment">#独立模型选择，论文中提到过三种区分意图向量包含信息的算法：向量距离，余弦相似度，互信息</span></span><br><span class="line">        self.device = torch.device(<span class="string">"cuda:"</span> + str(args_config.gpu_id)) <span class="keyword">if</span> args_config.cuda \</span><br><span class="line">                                                                      <span class="keyword">else</span> torch.device(<span class="string">"cpu"</span>)</span><br><span class="line"></span><br><span class="line">        self.adj_mat = adj_mat<span class="comment"># 传入的是 mean_adi_list[0]，均值化后的拉普拉斯矩阵，且矩阵裁剪后的形状为[userNum,itemNum]，</span></span><br><span class="line">        self.graph = graph<span class="comment"># 代表知识图谱，是由kg_final的三元组中提取的&lt;头结点，尾结点&gt;组成的有向图</span></span><br><span class="line">        self.edge_index, self.edge_type = self._get_edges(graph)<span class="comment">#[-1,2]，[-1,1]</span></span><br><span class="line"></span><br><span class="line">        self._init_weight()</span><br><span class="line">        self.all_embed = nn.Parameter(self.all_embed)</span><br><span class="line">        self.latent_emb = nn.Parameter(self.latent_emb)</span><br><span class="line"></span><br><span class="line">        self.gcn = self._init_model()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_weight</span><span class="params">(self)</span>:</span></span><br><span class="line">        initializer = nn.init.xavier_uniform_</span><br><span class="line">        self.all_embed = initializer(torch.empty(self.n_nodes, self.emb_size))</span><br><span class="line">        <span class="comment">#IG 和 KG 结点的嵌入向量初始化</span></span><br><span class="line">        self.latent_emb = initializer(torch.empty(self.n_factors, self.emb_size))</span><br><span class="line">		<span class="comment">#用户偏好的嵌入表示</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># [n_users, n_entities]？ 这里的形状应该是[n_users,n_items]</span></span><br><span class="line">        self.interact_mat = self._convert_sp_mat_to_sp_tensor(self.adj_mat).to(self.device)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_model</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> GraphConv(channel=self.emb_size,</span><br><span class="line">                         n_hops=self.context_hops,</span><br><span class="line">                         n_users=self.n_users,</span><br><span class="line">                         n_relations=self.n_relations,</span><br><span class="line">                         n_factors=self.n_factors,</span><br><span class="line">                         interact_mat=self.interact_mat,</span><br><span class="line">                         ind=self.ind,</span><br><span class="line">                         node_dropout_rate=self.node_dropout_rate,</span><br><span class="line">                         mess_dropout_rate=self.mess_dropout_rate)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_convert_sp_mat_to_sp_tensor</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        coo = X.tocoo()</span><br><span class="line">        i = torch.LongTensor([coo.row, coo.col])</span><br><span class="line">        v = torch.from_numpy(coo.data).float()</span><br><span class="line">        <span class="keyword">return</span> torch.sparse.FloatTensor(i, v, coo.shape)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_indices</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        coo = X.tocoo()</span><br><span class="line">        <span class="keyword">return</span> torch.LongTensor([coo.row, coo.col]).t()  <span class="comment"># [-1, 2]</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_edges</span><span class="params">(self, graph)</span>:</span></span><br><span class="line">        graph_tensor = torch.tensor(list(graph.edges))  <span class="comment"># [-1, 3]</span></span><br><span class="line">        index = graph_tensor[:, :<span class="number">-1</span>]  <span class="comment"># [-1, 2]</span></span><br><span class="line">        type = graph_tensor[:, <span class="number">-1</span>]  <span class="comment"># [-1, 1]</span></span><br><span class="line">        <span class="comment">#.t() 转置Tensor   long()将张量中各元素转为torch.int64类型数据 .to指定运算张量的设备</span></span><br><span class="line">        <span class="keyword">return</span> index.t().long().to(self.device), type.long().to(self.device)</span><br></pre></td></tr></table></figure>
<p>对_get_edges中的一些变量打印查看，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">print(list(graph.edges)[0:5])</span><br><span class="line">print(graph_tensor.shape)</span><br><span class="line">print(index.shape)</span><br><span class="line">print(graph_tensor[:, -1].shape)</span><br><span class="line">==&gt;</span><br><span class="line">[(0, 48123, 1), (0, 73455, 2), (0, 80230, 2), (0, 91668, 2), (0, 91810, 2)]</span><br><span class="line">torch.Size([929134, 3])</span><br><span class="line">torch.Size([929134, 2])</span><br><span class="line">torch.Size([929134])</span><br></pre></td></tr></table></figure>
<p>根据之前的分析，结合这里的打印信息可以知道，graph_tensor存储的数据格式为[entityId，entityId，relationId]。为了进一步验证分析，查看Networkx文档，搜索<strong>networkx.MultiGraph.edges</strong>可知graph.edges返回<strong>[u,</strong> <strong>v,</strong> <strong>k]</strong>格式的数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, batch=None)</span>:</span></span><br><span class="line">    user = batch[<span class="string">'users'</span>]</span><br><span class="line">    pos_item = batch[<span class="string">'pos_items'</span>]</span><br><span class="line">    neg_item = batch[<span class="string">'neg_items'</span>]</span><br><span class="line"></span><br><span class="line">    user_emb = self.all_embed[:self.n_users, :]</span><br><span class="line">    item_emb = self.all_embed[self.n_users:, :]</span><br><span class="line">    <span class="comment">#channel 的 值等于emb_size等于输入的dim   , 即'embedding size'</span></span><br><span class="line">    <span class="comment"># entity_gcn_emb: [n_entity, channel]</span></span><br><span class="line">    <span class="comment"># user_gcn_emb: [n_users, channel]</span></span><br><span class="line">    entity_gcn_emb, user_gcn_emb, cor = self.gcn(user_emb,</span><br><span class="line">                                                 item_emb,</span><br><span class="line">                                                 self.latent_emb,</span><br><span class="line">                                                 self.edge_index,</span><br><span class="line">                                                 self.edge_type,</span><br><span class="line">                                                 self.interact_mat,</span><br><span class="line">                                                 mess_dropout=self.mess_dropout,</span><br><span class="line">                                                 node_dropout=self.node_dropout)</span><br><span class="line">    u_e = user_gcn_emb[user]</span><br><span class="line">    pos_e, neg_e = entity_gcn_emb[pos_item], entity_gcn_emb[neg_item]</span><br><span class="line">    <span class="keyword">return</span> self.create_bpr_loss(u_e, pos_e, neg_e, cor)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate</span><span class="params">(self)</span>:</span></span><br><span class="line">    user_emb = self.all_embed[:self.n_users, :]</span><br><span class="line">    item_emb = self.all_embed[self.n_users:, :]</span><br><span class="line">    <span class="keyword">return</span> self.gcn(user_emb,</span><br><span class="line">                    item_emb,</span><br><span class="line">                    self.latent_emb,</span><br><span class="line">                    self.edge_index,</span><br><span class="line">                    self.edge_type,</span><br><span class="line">                    self.interact_mat,</span><br><span class="line">                    mess_dropout=<span class="literal">False</span>, node_dropout=<span class="literal">False</span>)[:<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rating</span><span class="params">(self, u_g_embeddings, i_g_embeddings)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> torch.matmul(u_g_embeddings, i_g_embeddings.t())</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_bpr_loss</span><span class="params">(self, users, pos_items, neg_items, cor)</span>:</span></span><br><span class="line">    batch_size = users.shape[<span class="number">0</span>]</span><br><span class="line">    pos_scores = torch.sum(torch.mul(users, pos_items), axis=<span class="number">1</span>)</span><br><span class="line">    neg_scores = torch.sum(torch.mul(users, neg_items), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    mf_loss = <span class="number">-1</span> * torch.mean(nn.LogSigmoid()(pos_scores - neg_scores))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># cul regularizer</span></span><br><span class="line">    regularizer = (torch.norm(users) ** <span class="number">2</span></span><br><span class="line">                   + torch.norm(pos_items) ** <span class="number">2</span></span><br><span class="line">                   + torch.norm(neg_items) ** <span class="number">2</span>) / <span class="number">2</span></span><br><span class="line">    emb_loss = self.decay * regularizer / batch_size</span><br><span class="line">    cor_loss = self.sim_decay * cor</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mf_loss + emb_loss + cor_loss, mf_loss, emb_loss, cor</span><br></pre></td></tr></table></figure>

    </div>

    
    
    
        
      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/RecSys/" rel="tag"># RecSys</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2021/09/06/RecSearchAuditionReady/" rel="next" title="RecSearchAuditionReady">
                  <i class="fa fa-chevron-left"></i> RecSearchAuditionReady
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2021/11/12/PytorchLearn/" rel="prev" title="PytorchLearn">
                  PytorchLearn <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    
      <script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
      <script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
      <div class="widget-wrap">
          <h3 class="widget-title">Tag Cloud</h3>
          <div id="myCanvasContainer" class="widget tagcloud">
              <canvas width="250" height="250" id="resCanvas" style="width=100%">
                  <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm-and-Data-Structure/">Algorithm and Data Structure</a><span class="tag-list-count">17</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Leetcode/">Leetcode</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Luogu/">Luogu</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RecSys/">RecSys</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Reptile/">Reptile</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/WHIMSY/">WHIMSY</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dp/">dp</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jobHunting/">jobHunting</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a><span class="tag-list-count">1</span></li></ul>
              </canvas>
          </div>
      </div>
    
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#源码目录结构"><span class="nav-number">1.</span> <span class="nav-text">源码目录结构</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#data"><span class="nav-number">2.</span> <span class="nav-text">data</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#amazon-book"><span class="nav-number">2.1.</span> <span class="nav-text">amazon-book</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#源码中的一些技术-库简介"><span class="nav-number">3.</span> <span class="nav-text">源码中的一些技术/库简介</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#tqdm"><span class="nav-number">3.1.</span> <span class="nav-text">tqdm</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图结构表示"><span class="nav-number">3.2.</span> <span class="nav-text">图结构表示</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#稀疏矩阵"><span class="nav-number">3.3.</span> <span class="nav-text">稀疏矩阵</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#main-py"><span class="nav-number">4.</span> <span class="nav-text">main.py</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#设置随机种子"><span class="nav-number">4.1.</span> <span class="nav-text">设置随机种子</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#从命令行中读取参数"><span class="nav-number">4.2.</span> <span class="nav-text">从命令行中读取参数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#构建数据集"><span class="nav-number">4.3.</span> <span class="nav-text">构建数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#协同过滤数据"><span class="nav-number">4.4.</span> <span class="nav-text">协同过滤数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型定义"><span class="nav-number">4.5.</span> <span class="nav-text">模型定义</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#优化器定义"><span class="nav-number">4.6.</span> <span class="nav-text">优化器定义</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型训练"><span class="nav-number">4.7.</span> <span class="nav-text">模型训练</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#data-loader-py"><span class="nav-number">5.</span> <span class="nav-text">data_loader.py</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#evaluate-py"><span class="nav-number">6.</span> <span class="nav-text">evaluate.py</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#helper-py"><span class="nav-number">7.</span> <span class="nav-text">helper.py</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#metrics-py"><span class="nav-number">8.</span> <span class="nav-text">metrics.py</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#parser-py"><span class="nav-number">9.</span> <span class="nav-text">parser.py</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#KGIN-py"><span class="nav-number">10.</span> <span class="nav-text">KGIN.py</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Relational-Path-aware-Aggregation"><span class="nav-number">10.1.</span> <span class="nav-text">Relational Path-aware Aggregation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-2-Aggregation-Layer-over-Knowledge-Graph"><span class="nav-number">10.1.0.1.</span> <span class="nav-text">3.2.2 Aggregation Layer over Knowledge Graph</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-1-Aggregation-Layer-over-Intent-Graph"><span class="nav-number">10.1.0.2.</span> <span class="nav-text">3.2.1 Aggregation Layer over Intent Graph.</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图卷积网络"><span class="nav-number">10.2.</span> <span class="nav-text">图卷积网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#衡量向量间信息量相同程度"><span class="nav-number">10.2.1.</span> <span class="nav-text">衡量向量间信息量相同程度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#图卷积网络前向计算"><span class="nav-number">10.2.2.</span> <span class="nav-text">图卷积网络前向计算</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#推荐模型"><span class="nav-number">10.3.</span> <span class="nav-text">推荐模型</span></a></li></ol></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/MyAvatar.jpg"
      alt="李松">
  <p class="site-author-name" itemprop="name">李松</p>
  <div class="site-description" itemprop="description">NoGameNoLife</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">50</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">标签</span>
        
      </div>
    
  </nav>
</div>



      </div>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2023</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">李松</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">213k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">3:13</span>
</div>



        












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.1"></script><script src="/js/motion.js?v=7.4.1"></script>
<script src="/js/schemes/pisces.js?v=7.4.1"></script>

<script src="/js/next-boot.js?v=7.4.1"></script>



  








  <script src="/js/local-search.js?v=7.4.1"></script>














  

  

  

  


  
    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas> 
    <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script> 
    <script type="text/javascript" src="/js/src/fireworks.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/miku.model.json"},"display":{"position":"right","width":250,"height":500},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
